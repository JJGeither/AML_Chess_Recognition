{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in test:  20000\n",
      "Files in train:  80000\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "# opens the chess boards.zip file into the chessBoards object\n",
    "zipFilePath = './archive.zip'\n",
    "chessBoards = ZipFile(zipFilePath, 'r')\n",
    "\n",
    "#datasetTest = []\n",
    "#datasetTrain = []\n",
    "test = []\n",
    "train = []\n",
    "newpath = True\n",
    "\n",
    "# extract the file names from the train and test folders in the zip archive\n",
    "for file in chessBoards.namelist():\n",
    "    # fills the file names from within the dataset subfolder\n",
    "    \"\"\"if file[:13] == 'dataset/test/':\n",
    "        datasetTest.append(file)\n",
    "    if file[:14] == 'dataset/train/':\n",
    "        datasetTrain.append(file)\"\"\"\n",
    "\n",
    "    if file[:4] == 'test':\n",
    "        test.append(file)\n",
    "    if file[:5] == 'train':\n",
    "        train.append(file)\n",
    "\n",
    "    # find any new file paths not accounted for\n",
    "    \"\"\"if file[:13] != 'dataset/test/' and \\\n",
    "        file[:14] != 'dataset/train/' and \\\n",
    "        file[:4] != 'test'and \\\n",
    "        file[:5] != 'train' and \\\n",
    "        newpath:\n",
    "        print(\"new path: \", file)\n",
    "        newpath = False\"\"\"\n",
    "\n",
    "print(\"Files in test: \", len(test))\n",
    "print(\"Files in train: \", len(train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted and saved to .\\test_data_100.pickle\n",
      "Data extracted and saved to .\\train_data_1000.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import random\n",
    "\n",
    "# Extracts the data from the zip file and saves it to a pickle file\n",
    "#\n",
    "# @param[in] zipFilePath - the path to the zip file\n",
    "# @param[in] outputPickleFile - the path to the pickle file to save the data to\n",
    "# @param[in] directory - the directory within the zip file to extract the data from\n",
    "# @param[in] sampleAmount - the number of samples to extract from the zip file\n",
    "def extractData(zipFilePath, outputPickleFile, directory='test/', sampleAmount=None):\n",
    "    data = []\n",
    "\n",
    "    with ZipFile(zipFilePath, 'r') as chess_boards:\n",
    "        # Get all file names in the zip file that start with the directory\n",
    "        file_names = [name for name in chess_boards.namelist() if name.startswith(directory)]\n",
    "\n",
    "        # Shuffle the file names to get a random sample\n",
    "        random.shuffle(file_names)\n",
    "\n",
    "        for file_name in file_names:\n",
    "            if file_name.startswith(directory):\n",
    "                # Extract FEN string from file name\n",
    "                fen_string = file_name.split('/')[-1]\n",
    "\n",
    "                # Extract image bytes and convert to PIL Image\n",
    "                with chess_boards.open(file_name) as image_file:\n",
    "                    image_bytes = image_file.read()\n",
    "                    image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "                    # Converts image to grayscale\n",
    "                    image = image.convert('L')\n",
    "\n",
    "                    data.append((fen_string, image))\n",
    "\n",
    "                # Check if the desired number of samples is reached\n",
    "                if sampleAmount is not None and len(data) >= sampleAmount:\n",
    "                    break\n",
    "\n",
    "    # Get the directory path and base filename\n",
    "    output_dir, base_filename = os.path.split(outputPickleFile)\n",
    "    \n",
    "    # Include the number of samples in the base filename\n",
    "    if sampleAmount is not None:\n",
    "        base_filename = f\"{os.path.splitext(base_filename)[0]}_{sampleAmount}.pickle\"\n",
    "    \n",
    "    # Construct the full output pickle file path\n",
    "    outputPickleFile = os.path.join(output_dir, base_filename)\n",
    "\n",
    "    # Save data to pickle file\n",
    "    with open(outputPickleFile, 'wb') as pickle_file:\n",
    "        pickle.dump(data, pickle_file)\n",
    "\n",
    "    print(f\"Data extracted and saved to {outputPickleFile}\")\n",
    "\n",
    "# Entry point to start the process of pickling the data\n",
    "def pickleData():\n",
    "    zipFilePath = './archive.zip'\n",
    "    outputPickleFile = './test_data.pickle'\n",
    "    extractData(zipFilePath, outputPickleFile, \"test/\", 100)\n",
    "\n",
    "    outputPickleFile = './train_data.pickle'\n",
    "    extractData(zipFilePath, outputPickleFile, \"train/\", 1000)\n",
    "\n",
    "pickleData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ./train_data_1000.pickle\n",
      "Loading data from ./test_data_100.pickle\n",
      "Preparing training data...\n",
      "Preparing test data...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Model accuracy: 0.83046875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "pieceLabels = ['p', 'r', 'n', 'b', 'q', 'k', 'P', 'R', 'N', 'B', 'Q', 'K']\n",
    "\n",
    "# Loads the data from the pickle file\n",
    "#\n",
    "# @param[in] file_path - the path to the pickle file\n",
    "# @return - the data loaded from the pickle file\n",
    "def loadData(file_path):\n",
    "    print(f\"Loading data from {file_path}\")\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "# Splits the image into 50x50 chunks\n",
    "#\n",
    "# @param[in] image - the image to split\n",
    "# @return - a list of 50x50 chunks\n",
    "def splitIntoChunks(image):\n",
    "    chunks = []\n",
    "    width, height = image.size\n",
    "    for y in range(0, height, 50):\n",
    "        for x in range(0, width, 50):\n",
    "            chunk = image.crop((x, y, x + 50, y + 50))\n",
    "            chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "# Prepares the data for training\n",
    "#\n",
    "# @param[in] data - the data to prepare\n",
    "# @return - the prepared data\n",
    "def prepareData(data):\n",
    "    X = []\n",
    "    y = []\n",
    "    for fen_string, image in data:\n",
    "        chunks = splitIntoChunks(image)\n",
    "        for chunk in chunks:\n",
    "\n",
    "            # Convert the chunk to a numpy array and flatten it\n",
    "            chunk = np.array(chunk).flatten()\n",
    "            X.append(chunk)\n",
    "\n",
    "            # Label corresponding to the piece\n",
    "            if fen_string:\n",
    "                pieceLabel = fen_string[0] if fen_string[0] in pieceLabels else ' '\n",
    "                y.append(pieceLabel)\n",
    "\n",
    "                # Update fen_string to remove the piece label\n",
    "                fen_string = fen_string[1:]\n",
    "            else:\n",
    "                y.append(' ')\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Trains a model using the training data from the pickle file\n",
    "#\n",
    "# @param[in] X_train - the training data\n",
    "# @param[in] y_train - the training labels\n",
    "# @return - the trained model\n",
    "def trainModel(X_train, y_train):\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=None)\n",
    "    print(\"Training model...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Evaluates the model using the test data from the pickle file\n",
    "#\n",
    "# @param[in] model - the model to evaluate\n",
    "# @param[in] X_test - the test data\n",
    "# @param[in] y_test - the test labels\n",
    "def evaluateModel(model, X_test, y_test):\n",
    "    print(\"Evaluating model...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model accuracy: {accuracy}\")\n",
    "\n",
    "# Entry point to start the process of training and evaluating the model\n",
    "def main():\n",
    "    # Load the data\n",
    "    train_data = loadData('./train_data_1000.pickle')\n",
    "    test_data = loadData('./test_data_100.pickle')\n",
    "\n",
    "    # Prepare the data\n",
    "    print(\"Preparing training data...\")\n",
    "    X_train, y_train = prepareData(train_data)\n",
    "    print(\"Preparing test data...\")\n",
    "    X_test, y_test = prepareData(test_data)\n",
    "\n",
    "    # Train the model\n",
    "    model = trainModel(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    evaluateModel(model, X_test, y_test)\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
