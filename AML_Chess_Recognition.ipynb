{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in test:  20000\n",
      "Files in train:  80000\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "# opens the chess boards.zip file into the chessBoards object\n",
    "zipFilePath = './archive.zip'\n",
    "chessBoards = ZipFile(zipFilePath, 'r')\n",
    "\n",
    "#datasetTest = []\n",
    "#datasetTrain = []\n",
    "test = []\n",
    "train = []\n",
    "newpath = True\n",
    "\n",
    "# extract the file names from the train and test folders in the zip archive\n",
    "for file in chessBoards.namelist():\n",
    "    # fills the file names from within the dataset subfolder\n",
    "    \"\"\"if file[:13] == 'dataset/test/':\n",
    "        datasetTest.append(file)\n",
    "    if file[:14] == 'dataset/train/':\n",
    "        datasetTrain.append(file)\"\"\"\n",
    "\n",
    "    if file[:4] == 'test':\n",
    "        test.append(file)\n",
    "    if file[:5] == 'train':\n",
    "        train.append(file)\n",
    "\n",
    "    # find any new file paths not accounted for\n",
    "    \"\"\"if file[:13] != 'dataset/test/' and \\\n",
    "        file[:14] != 'dataset/train/' and \\\n",
    "        file[:4] != 'test'and \\\n",
    "        file[:5] != 'train' and \\\n",
    "        newpath:\n",
    "        print(\"new path: \", file)\n",
    "        newpath = False\"\"\"\n",
    "\n",
    "print(\"Files in test: \", len(test))\n",
    "print(\"Files in train: \", len(train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted and saved to .\\test_data_100.pickle\n",
      "Data extracted and saved to .\\train_data_1000.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import random\n",
    "\n",
    "# Extracts the data from the zip file and saves it to a pickle file\n",
    "#\n",
    "# @param[in] zipFilePath - the path to the zip file\n",
    "# @param[in] outputPickleFile - the path to the pickle file to save the data to\n",
    "# @param[in] directory - the directory within the zip file to extract the data from\n",
    "# @param[in] sampleAmount - the number of samples to extract from the zip file\n",
    "def extractData(zipFilePath, outputPickleFile, directory='test/', sampleAmount=None):\n",
    "    data = []\n",
    "\n",
    "    with ZipFile(zipFilePath, 'r') as chess_boards:\n",
    "        # Get all file names in the zip file that start with the directory\n",
    "        file_names = [name for name in chess_boards.namelist() if name.startswith(directory)]\n",
    "\n",
    "        # Shuffle the file names to get a random sample\n",
    "        random.shuffle(file_names)\n",
    "\n",
    "        for file_name in file_names:\n",
    "            if file_name.startswith(directory):\n",
    "                # Extract FEN string from file name\n",
    "                fen_string = file_name.split('/')[-1]\n",
    "\n",
    "                # Extract image bytes and convert to PIL Image\n",
    "                with chess_boards.open(file_name) as image_file:\n",
    "                    image_bytes = image_file.read()\n",
    "                    image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "                    # Converts image to grayscale\n",
    "                    image = image.convert('L')\n",
    "\n",
    "                    data.append((fen_string, image))\n",
    "\n",
    "                # Check if the desired number of samples is reached\n",
    "                if sampleAmount is not None and len(data) >= sampleAmount:\n",
    "                    break\n",
    "\n",
    "    # Get the directory path and base filename\n",
    "    output_dir, base_filename = os.path.split(outputPickleFile)\n",
    "    \n",
    "    # Include the number of samples in the base filename\n",
    "    if sampleAmount is not None:\n",
    "        base_filename = f\"{os.path.splitext(base_filename)[0]}_{sampleAmount}.pickle\"\n",
    "    \n",
    "    # Construct the full output pickle file path\n",
    "    outputPickleFile = os.path.join(output_dir, base_filename)\n",
    "\n",
    "    # Save data to pickle file\n",
    "    with open(outputPickleFile, 'wb') as pickle_file:\n",
    "        pickle.dump(data, pickle_file)\n",
    "\n",
    "    print(f\"Data extracted and saved to {outputPickleFile}\")\n",
    "\n",
    "# Entry point to start the process of pickling the data\n",
    "def pickleData():\n",
    "    zipFilePath = './archive.zip'\n",
    "    outputPickleFile = './test_data.pickle'\n",
    "    extractData(zipFilePath, outputPickleFile, \"test/\", 100)\n",
    "\n",
    "    outputPickleFile = './train_data.pickle'\n",
    "    extractData(zipFilePath, outputPickleFile, \"train/\", 1000)\n",
    "\n",
    "pickleData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from pickle file...\n",
      "Extracting images and labels from training data...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 78\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m     76\u001b[0m     evaluateModel(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./test_data_100.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 78\u001b[0m main()\n",
      "Cell \u001b[1;32mIn[6], line 72\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     model \u001b[38;5;241m=\u001b[39m trainModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./train_data_1000.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel trained\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 30\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m(trainingDataFile)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Extract the images and labels from the data\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting images and labels from training data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m X_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m trainingData])\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Extract labels from filenames\u001b[39;00m\n\u001b[0;32m     33\u001b[0m y_train \u001b[38;5;241m=\u001b[39m [fenToLabel(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m trainingData]\n",
      "Cell \u001b[1;32mIn[6], line 30\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Extract the images and labels from the data\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting images and labels from training data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m X_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m trainingData])\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Extract labels from filenames\u001b[39;00m\n\u001b[0;32m     33\u001b[0m y_train \u001b[38;5;241m=\u001b[39m [fenToLabel(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m trainingData]\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "pieceLabels = ['p', 'r', 'n', 'b', 'q', 'k', 'P', 'R', 'N', 'B', 'Q', 'K']\n",
    "\n",
    "# Maps a FEN string to a label\n",
    "#\n",
    "# @param[in] fenString - the FEN string to map to a label\n",
    "# @return - the label corresponding to the FEN string\n",
    "def fenToLabel(fenString):\n",
    "    if fenString.isalpha():\n",
    "        return fenString\n",
    "    elif fenString.isdigit():\n",
    "        return '1' * int(fenString)\n",
    "\n",
    "# Trains a model using the training data from the pickle file\n",
    "#\n",
    "# @param[in] trainingDataFile - the path to the pickle file containing the training data\n",
    "# @return - the trained Random Forest model\n",
    "def trainModel(trainingDataFile):\n",
    "    # Load the training data from the pickle file\n",
    "    print(\"Loading training data from pickle file...\")\n",
    "    with open(trainingDataFile, 'rb') as file:\n",
    "        trainingData = pickle.load(file)\n",
    "\n",
    "    # Extract the images and labels from the data\n",
    "    print(\"Extracting images and labels from training data...\")\n",
    "    X_train = np.array([np.array(data[1]) for data in trainingData])\n",
    "\n",
    "    # Extract labels from filenames\n",
    "    y_train = [fenToLabel(data[0]) for data in trainingData]\n",
    "\n",
    "    # Reshape the images to 1D arrays\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    print(\"Training model...\")\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=None)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluateModel(model, testDataFile):\n",
    "    # Load the test data from the pickle file\n",
    "    print(\"Loading test data from pickle file...\")\n",
    "    with open(testDataFile, 'rb') as file:\n",
    "        testData = pickle.load(file)\n",
    "\n",
    "    # Extract the images and labels from the data\n",
    "    print(\"Extracting images and labels from test data...\")\n",
    "    X_test = np.array([np.array(data[1]) for data in testData])\n",
    "    y_test = [fenToLabel(data[0]) for data in testData]\n",
    "\n",
    "    # Predict the labels using the model\n",
    "    print(\"Predicting labels...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model using accuracy\n",
    "    print(\"Evaluating accuracy...\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model accuracy: {accuracy}\")\n",
    "\n",
    "    for actual, pred in zip(y_test[:5], y_pred[:5]):\n",
    "        print(f\"Actual: {actual}, Predicted: {pred}\")\n",
    "\n",
    "# Entry point to train the model and evaluate it\n",
    "def main():\n",
    "\n",
    "    # Train\n",
    "    model = trainModel('./train_data_1000.pickle')\n",
    "    print(\"Model trained\")\n",
    "\n",
    "    # Evaluate\n",
    "    evaluateModel(model, './test_data_100.pickle')\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
