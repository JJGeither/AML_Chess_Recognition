{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in test:  20000\n",
      "Files in train:  80000\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "# opens the chess boards.zip file into the chessBoards object\n",
    "zipFilePath = './archive.zip'\n",
    "chessBoards = ZipFile(zipFilePath, 'r')\n",
    "\n",
    "#datasetTest = []\n",
    "#datasetTrain = []\n",
    "test = []\n",
    "train = []\n",
    "newpath = True\n",
    "\n",
    "# extract the file names from the train and test folders in the zip archive\n",
    "for file in chessBoards.namelist():\n",
    "    # fills the file names from within the dataset subfolder\n",
    "    \"\"\"if file[:13] == 'dataset/test/':\n",
    "        datasetTest.append(file)\n",
    "    if file[:14] == 'dataset/train/':\n",
    "        datasetTrain.append(file)\"\"\"\n",
    "\n",
    "    if file[:4] == 'test':\n",
    "        test.append(file)\n",
    "    if file[:5] == 'train':\n",
    "        train.append(file)\n",
    "\n",
    "    # find any new file paths not accounted for\n",
    "    \"\"\"if file[:13] != 'dataset/test/' and \\\n",
    "        file[:14] != 'dataset/train/' and \\\n",
    "        file[:4] != 'test'and \\\n",
    "        file[:5] != 'train' and \\\n",
    "        newpath:\n",
    "        print(\"new path: \", file)\n",
    "        newpath = False\"\"\"\n",
    "\n",
    "print(\"Files in test: \", len(test))\n",
    "print(\"Files in train: \", len(train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted and saved to .\\test_data_100.pickle\n",
      "Data extracted and saved to .\\train_data_10000.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import random\n",
    "\n",
    "# Extracts the data from the zip file and saves it to a pickle file\n",
    "#\n",
    "# @param[in] zipFilePath - the path to the zip file\n",
    "# @param[in] outputPickleFile - the path to the pickle file to save the data to\n",
    "# @param[in] directory - the directory within the zip file to extract the data from\n",
    "# @param[in] sampleAmount - the number of samples to extract from the zip file\n",
    "def extractData(zipFilePath, outputPickleFile, directory='test/', sampleAmount=None):\n",
    "    data = []\n",
    "\n",
    "    with ZipFile(zipFilePath, 'r') as chess_boards:\n",
    "        # Get all file names in the zip file that start with the directory\n",
    "        file_names = [name for name in chess_boards.namelist() if name.startswith(directory)]\n",
    "\n",
    "        # Shuffle the file names to get a random sample\n",
    "        random.shuffle(file_names)\n",
    "\n",
    "        for file_name in file_names:\n",
    "            if file_name.startswith(directory):\n",
    "                # Extract FEN string from file name\n",
    "                fen_string = file_name.split('/')[-1]\n",
    "\n",
    "                # Extract image bytes and convert to PIL Image\n",
    "                with chess_boards.open(file_name) as image_file:\n",
    "                    image_bytes = image_file.read()\n",
    "                    image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "                    # Converts image to grayscale\n",
    "                    image = image.convert('L')\n",
    "\n",
    "                    data.append((fen_string, image))\n",
    "\n",
    "                # Check if the desired number of samples is reached\n",
    "                if sampleAmount is not None and len(data) >= sampleAmount:\n",
    "                    break\n",
    "\n",
    "    # Get the directory path and base filename\n",
    "    output_dir, base_filename = os.path.split(outputPickleFile)\n",
    "    \n",
    "    # Include the number of samples in the base filename\n",
    "    if sampleAmount is not None:\n",
    "        base_filename = f\"{os.path.splitext(base_filename)[0]}_{sampleAmount}.pickle\"\n",
    "    \n",
    "    # Construct the full output pickle file path\n",
    "    outputPickleFile = os.path.join(output_dir, base_filename)\n",
    "\n",
    "    # Save data to pickle file\n",
    "    with open(outputPickleFile, 'wb') as pickle_file:\n",
    "        pickle.dump(data, pickle_file)\n",
    "\n",
    "    print(f\"Data extracted and saved to {outputPickleFile}\")\n",
    "\n",
    "# Entry point to start the process of pickling the data\n",
    "def pickleData():\n",
    "    zipFilePath = './archive.zip'\n",
    "    outputPickleFile = './test_data.pickle'\n",
    "    extractData(zipFilePath, outputPickleFile, \"test/\", 100)\n",
    "\n",
    "    outputPickleFile = './train_data.pickle'\n",
    "    extractData(zipFilePath, outputPickleFile, \"train/\", 10000)\n",
    "\n",
    "pickleData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ./train_data_1000.pickle\n",
      "Loading data from ./test_data_100.pickle\n",
      "Preparing training data...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 121\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     evaluateModel(model, X_test, y_test)\n\u001b[1;32m--> 121\u001b[0m main()\n",
      "Cell \u001b[1;32mIn[63], line 111\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Prepare the data\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreparing training data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 111\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m prepareData(train_data, maxEmptySpaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreparing test data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    113\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m prepareData(test_data, isTestingData\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[63], line 56\u001b[0m, in \u001b[0;36mprepareData\u001b[1;34m(data, maxEmptySpaces, isTestingData)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m piece \u001b[38;5;129;01min\u001b[39;00m board\u001b[38;5;241m.\u001b[39mpiece_map():\n\u001b[0;32m     55\u001b[0m     piece_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(piece)\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m---> 56\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m chess\u001b[38;5;241m.\u001b[39mFILE_NAMES[piece\u001b[38;5;241m.\u001b[39mfile], chess\u001b[38;5;241m.\u001b[39mRANK_NAMES[piece\u001b[38;5;241m.\u001b[39mrank]\n\u001b[0;32m     57\u001b[0m     board_representation[row, col] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m piece_type \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Combine image data and board representation into a single feature vector\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'file'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import chess\n",
    "\n",
    "pieceLabels = ['p', 'r', 'n', 'b', 'q', 'k', 'P', 'R', 'N', 'B', 'Q', 'K']\n",
    "\n",
    "# Loads the data from the pickle file\n",
    "#\n",
    "# @param[in] file_path - the path to the pickle file\n",
    "# @return - the data loaded from the pickle file\n",
    "def loadData(file_path):\n",
    "    print(f\"Loading data from {file_path}\")\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "# Splits the image into 50x50 chunks\n",
    "#\n",
    "# @param[in] image - the image to split\n",
    "# @return - a list of 50x50 chunks\n",
    "def splitIntoChunks(image):\n",
    "    chunks = []\n",
    "    width, height = image.size\n",
    "    for y in range(0, height, 50):\n",
    "        for x in range(0, width, 50):\n",
    "            chunk = image.crop((x, y, x + 50, y + 50))\n",
    "            chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "# Prepares the data for training\n",
    "#\n",
    "# @param[in] data - the data to prepare\n",
    "# @return - the prepared data\n",
    "def prepareData(data, maxEmptySpaces=None, isTestingData=False):\n",
    "    X = []  # List to store image data\n",
    "    y = []  # List to store labels\n",
    "\n",
    "    for fen_string, image in data:\n",
    "        # Remove file extension from FEN string\n",
    "        fen_string = fen_string.split('.')[0]\n",
    "\n",
    "        fen_string = fen_string.replace(\"-\", \"/\")\n",
    "\n",
    "        # Process FEN string using chess.Board\n",
    "        board = chess.Board(fen_string)\n",
    "\n",
    "        # Convert board to a suitable feature representation (replace with your logic)\n",
    "        # This example creates a 8x8 binary matrix representing piece locations\n",
    "        board_representation = np.zeros((8, 8), dtype=np.float32)\n",
    "        for piece in board.piece_map():\n",
    "            piece_type = str(piece).split()[0].lower()\n",
    "            row, col = chess.FILE_NAMES[piece.file], chess.RANK_NAMES[piece.rank]\n",
    "            board_representation[row, col] = 1 if piece_type != '.' else 0\n",
    "\n",
    "        # Combine image data and board representation into a single feature vector\n",
    "        flattened_image = image.flatten()  # Flatten the image data\n",
    "        features = np.concatenate((flattened_image, board_representation.flatten()))\n",
    "\n",
    "        X.append(features)\n",
    "\n",
    "        # Get the label from the FEN string (e.g., the first character)\n",
    "        label = fen_string[0].lower()  # Assuming the first letter represents the active player's piece\n",
    "\n",
    "        # If it's testing data and there are only empty spaces, skip labeling (optional)\n",
    "        if isTestingData and len(fen_string.replace(\".\", \"\").replace(\"/\", \"\")) == maxEmptySpaces:\n",
    "            label = ' '  # Assign empty space label for testing\n",
    "\n",
    "        y.append(label)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Trains a model using the training data from the pickle file\n",
    "#\n",
    "# @param[in] X_train - the training data\n",
    "# @param[in] y_train - the training labels\n",
    "# @return - the trained model\n",
    "def trainModel(X_train, y_train):\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=None)\n",
    "    print(\"Training model...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Evaluates the model using the test data from the pickle file\n",
    "#\n",
    "# @param[in] model - the model to evaluate\n",
    "# @param[in] X_test - the test data\n",
    "# @param[in] y_test - the test labels\n",
    "def evaluateModel(model, X_test, y_test):\n",
    "    print(\"Evaluating model...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model accuracy: {accuracy}\")\n",
    "\n",
    "    for real, pred in zip(y_test, y_pred):\n",
    "        if real != ' ':\n",
    "            print(f\"Real: {real}, Predicted: {pred}\")\n",
    "\n",
    "# Entry point to start the process of training and evaluating the model\n",
    "def main():\n",
    "    # Load the data\n",
    "    train_data = loadData('./train_data_1000.pickle')\n",
    "    test_data = loadData('./test_data_100.pickle')\n",
    "\n",
    "    # Prepare the data\n",
    "    print(\"Preparing training data...\")\n",
    "    X_train, y_train = prepareData(train_data, maxEmptySpaces=50)\n",
    "    print(\"Preparing test data...\")\n",
    "    X_test, y_test = prepareData(test_data, isTestingData=True)\n",
    "\n",
    "    # Train the model\n",
    "    model = trainModel(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    evaluateModel(model, X_test, y_test)\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
