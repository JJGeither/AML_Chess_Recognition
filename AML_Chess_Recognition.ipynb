{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in test:  20000\n",
      "Files in train:  80000\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "# opens the chess boards.zip file into the chessBoards object\n",
    "zipFilePath = './archive.zip'\n",
    "chessBoards = ZipFile(zipFilePath, 'r')\n",
    "\n",
    "#datasetTest = []\n",
    "#datasetTrain = []\n",
    "test = []\n",
    "train = []\n",
    "newpath = True\n",
    "\n",
    "# extract the file names from the train and test folders in the zip archive\n",
    "for file in chessBoards.namelist():\n",
    "    # fills the file names from within the dataset subfolder\n",
    "    \"\"\"if file[:13] == 'dataset/test/':\n",
    "        datasetTest.append(file)\n",
    "    if file[:14] == 'dataset/train/':\n",
    "        datasetTrain.append(file)\"\"\"\n",
    "\n",
    "    if file[:4] == 'test':\n",
    "        test.append(file)\n",
    "    if file[:5] == 'train':\n",
    "        train.append(file)\n",
    "\n",
    "    # find any new file paths not accounted for\n",
    "    \"\"\"if file[:13] != 'dataset/test/' and \\\n",
    "        file[:14] != 'dataset/train/' and \\\n",
    "        file[:4] != 'test'and \\\n",
    "        file[:5] != 'train' and \\\n",
    "        newpath:\n",
    "        print(\"new path: \", file)\n",
    "        newpath = False\"\"\"\n",
    "\n",
    "print(\"Files in test: \", len(test))\n",
    "print(\"Files in train: \", len(train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted and saved to .\\test_data_100.pickle\n",
      "Data extracted and saved to .\\train_data_1000.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Extracts the data from the zip file and saves it to a pickle file\n",
    "#\n",
    "# @param[in] zipFilePath - the path to the zip file\n",
    "# @param[in] outputPickleFile - the path to the pickle file to save the data to\n",
    "# @param[in] directory - the directory within the zip file to extract the data from\n",
    "# @param[in] num_samples - the number of samples to extract from the zip file\n",
    "def extractData(zipFilePath, outputPickleFile, directory='test/', num_samples=None):\n",
    "    data = []\n",
    "\n",
    "    with ZipFile(zipFilePath, 'r') as chess_boards:\n",
    "        for file_name in chess_boards.namelist():\n",
    "            if file_name.startswith(directory):\n",
    "                # Extract FEN string from file name\n",
    "                fen_string = file_name.split('/')[-1]\n",
    "\n",
    "                # Extract image bytes and convert to PIL Image\n",
    "                with chess_boards.open(file_name) as image_file:\n",
    "                    image_bytes = image_file.read()\n",
    "                    image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "                    # Converts image to grayscale\n",
    "                    image = image.convert('L')\n",
    "\n",
    "                # Append FEN string and image to data\n",
    "                data.append((fen_string, image))\n",
    "\n",
    "                # Check if the desired number of samples is reached\n",
    "                if num_samples is not None and len(data) >= num_samples:\n",
    "                    break\n",
    "\n",
    "    # Get the directory path and base filename\n",
    "    output_dir, base_filename = os.path.split(outputPickleFile)\n",
    "    \n",
    "    # Include the number of samples in the base filename\n",
    "    if num_samples is not None:\n",
    "        base_filename = f\"{os.path.splitext(base_filename)[0]}_{num_samples}.pickle\"\n",
    "    \n",
    "    # Construct the full output pickle file path\n",
    "    outputPickleFile = os.path.join(output_dir, base_filename)\n",
    "\n",
    "    # Save data to pickle file\n",
    "    with open(outputPickleFile, 'wb') as pickle_file:\n",
    "        pickle.dump(data, pickle_file)\n",
    "\n",
    "    print(f\"Data extracted and saved to {outputPickleFile}\")\n",
    "\n",
    "# Entry point to start the process of pickling the data\n",
    "def pickleData():\n",
    "    zipFilePath = './archive.zip'\n",
    "    outputPickleFile = './test_data.pickle'\n",
    "    extractData(zipFilePath, outputPickleFile, \"test/\", 100)\n",
    "\n",
    "    outputPickleFile = './train_data.pickle'\n",
    "    extractData(zipFilePath, outputPickleFile, \"train/\", 1000)\n",
    "\n",
    "pickleData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from pickle file...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './train_data_1000.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     evaluateModel(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./test_data_100.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 59\u001b[0m main()\n",
      "Cell \u001b[1;32mIn[3], line 53\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     51\u001b[0m \n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m     model \u001b[38;5;241m=\u001b[39m trainModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./train_data_1000.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel trained\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m(trainingDataFile)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrainModel\u001b[39m(trainingDataFile):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Load the training data from the pickle file\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading training data from pickle file...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(trainingDataFile, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     15\u001b[0m         trainingData \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Extract the images and labels from the data\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train_data_1000.pickle'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Trains a model using the training data from the pickle file\n",
    "#\n",
    "# @param[in] trainingDataFile - the path to the pickle file containing the training data\n",
    "# @return - the trained Random Forest model\n",
    "def trainModel(trainingDataFile):\n",
    "    # Load the training data from the pickle file\n",
    "    print(\"Loading training data from pickle file...\")\n",
    "    with open(trainingDataFile, 'rb') as file:\n",
    "        trainingData = pickle.load(file)\n",
    "\n",
    "    # Extract the images and labels from the data\n",
    "    print(\"Extracting images and labels from training data...\")\n",
    "    X_train = np.array([np.array(data[1]).flatten() for data in trainingData])\n",
    "    y_train = [data[0] for data in trainingData]\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    print(\"Training model...\")\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=100, random_state=None)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluateModel(model, testDataFile):\n",
    "    # Load the test data from the pickle file\n",
    "    print(\"Loading test data from pickle file...\")\n",
    "    with open(testDataFile, 'rb') as file:\n",
    "        testData = pickle.load(file)\n",
    "\n",
    "    # Extract the images and labels from the data\n",
    "    print(\"Extracting images and labels from test data...\")\n",
    "    X_test = np.array([np.array(data[1]).flatten() for data in testData])\n",
    "    y_test = [data[0] for data in testData]\n",
    "\n",
    "    # Predict the labels using the model\n",
    "    print(\"Predicting labels...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model using accuracy\n",
    "    print(\"Evaluating accuracy...\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model accuracy: {accuracy}\")\n",
    "\n",
    "# Entry point to train the model and evaluate it\n",
    "def main():\n",
    "\n",
    "    # Train\n",
    "    model = trainModel('./train_data_1000.pickle')\n",
    "    print(\"Model trained\")\n",
    "\n",
    "    # Evaluate\n",
    "    evaluateModel(model, './test_data_100.pickle')\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
