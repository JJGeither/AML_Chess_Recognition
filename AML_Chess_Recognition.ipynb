{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from zipfile import ZipFile\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.feature import hog\n",
    "from skimage.io import imread\n",
    "from skimage import color, exposure\n",
    "from skimage.transform import rescale\n",
    "from skimage.util import view_as_blocks\n",
    "from multiprocessing import Pool\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import multiprocess as mp\n",
    "import pickle\n",
    "from multiprocessingNotebook import runt\n",
    "\n",
    "PICKLE_PATH = 'test_data.pickle'\n",
    "\n",
    "NUM_TRAINING_IMAGES = 500\n",
    "NUM_TESTING_IMAGES = 50\n",
    "\n",
    "NUM_SPACES_PER_BOARD = 2\n",
    "PICTURE_DIMENSIONS = 400\n",
    "block_width = PICTURE_DIMENSIONS // 8\n",
    "block_height = PICTURE_DIMENSIONS // 8\n",
    "num_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in test:  20000\n",
      "Files in train:  80000\n"
     ]
    }
   ],
   "source": [
    "# opens the chess boards.zip file into the chessBoards object\n",
    "zipFilePath = '../chess boards.zip'\n",
    "chessBoards = ZipFile(zipFilePath, 'r')\n",
    "\n",
    "test = []\n",
    "train = []\n",
    "newpath = True\n",
    "\n",
    "# extract the file names from the train and test folders in the zip archive\n",
    "for file in chessBoards.namelist():\n",
    "    # fills the file names from within the dataset subfolder\n",
    "    \"\"\"if file[:13] == 'dataset/test/':\n",
    "        datasetTest.append(file)\n",
    "    if file[:14] == 'dataset/train/':\n",
    "        datasetTrain.append(file)\"\"\"\n",
    "\n",
    "    if file[:4] == 'test':\n",
    "        test.append(file)\n",
    "    if file[:5] == 'train':\n",
    "        train.append(file)\n",
    "\n",
    "    # find any new file paths not accounted for\n",
    "    \"\"\"if file[:13] != 'dataset/test/' and \\\n",
    "        file[:14] != 'dataset/train/' and \\\n",
    "        file[:4] != 'test'and \\\n",
    "        file[:5] != 'train' and \\\n",
    "        newpath:\n",
    "        print(\"new path: \", file)\n",
    "        newpath = False\"\"\"\n",
    "\n",
    "print(\"Files in test: \", len(test))\n",
    "print(\"Files in train: \", len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel Loads Board Images for Training Purposes\n",
    "def HogTransform(img):\n",
    "    first_image_gray = color.rgb2gray(img)\n",
    "\n",
    "    fd, hog_image = hog(\n",
    "        first_image_gray,\n",
    "        orientations=8,\n",
    "        pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(1, 1),\n",
    "        visualize=True,\n",
    "        block_norm='L2-Hys',\n",
    "        feature_vector=True\n",
    "    )\n",
    "\n",
    "    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "    hog_image_uint8 = (hog_image_rescaled * 255).astype(np.uint8)\n",
    "    return hog_image_uint8\n",
    "\n",
    "def read_and_store_modified_chess_images():\n",
    "    return    \n",
    "\n",
    "def fen_from_position(position, fen_string):\n",
    "    rows = position // 8\n",
    "    cols = position % 8\n",
    "    \n",
    "    character = fen_string[rows * 8 + cols]\n",
    "\n",
    "    if character.isdigit():\n",
    "        return ' ' * int(character)\n",
    "    else:\n",
    "        return character\n",
    "\n",
    "def fen_from_filename(filename):\n",
    "    parts = filename.split('/')\n",
    "    fen_part = parts[-1].split('.')[0]\n",
    "\n",
    "    fen_string = ''.join([' ' * int(char) if char.isdigit() else char for char in fen_part])\n",
    "    fen_string = fen_string.replace('-', '')\n",
    "\n",
    "    return fen_string\n",
    "\n",
    "src = zipFilePath\n",
    "random.shuffle(train)\n",
    "print(\"Running...\")\n",
    "\n",
    "with mp.Pool(processes=7) as p:\n",
    "    args = [(fileName, src, fen_from_filename, fen_from_position, NUM_SPACES_PER_BOARD) for fileName in train[:NUM_TRAINING_IMAGES]]\n",
    "    results = p.starmap(runt, args)\n",
    "\n",
    "combined_results = {'fenstring': [], 'data': []}\n",
    "\n",
    "# Initialize lists to store all data and fenstring items\n",
    "all_data_items = []\n",
    "all_fenstring_items = []\n",
    "\n",
    "for result in results:\n",
    "    # Extend all_data_items with result['data']\n",
    "    all_data_items.extend(result['data'])\n",
    "    \n",
    "    # Extend all_fenstring_items with result['fenstring']\n",
    "    all_fenstring_items.extend(result['fenstring'])\n",
    "\n",
    "# Assign the combined lists to combined_results\n",
    "combined_results['data'] = all_data_items\n",
    "combined_results['fenstring'] = all_fenstring_items\n",
    "\n",
    "joblib.dump(combined_results, PICKLE_PATH)\n",
    "read_and_store_modified_chess_images()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential loads Board Images for Training Purposes\n",
    "def HogTransform(img):\n",
    "    first_image_gray = color.rgb2gray(img)\n",
    "\n",
    "    fd, hog_image = hog(\n",
    "        first_image_gray,\n",
    "        orientations=8,\n",
    "        pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(1, 1),\n",
    "        visualize=True,\n",
    "        block_norm='L2-Hys',\n",
    "        feature_vector=True\n",
    "    )\n",
    "\n",
    "    # Rescale histogram for better display\n",
    "    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "    hog_image_uint8 = (hog_image_rescaled * 255).astype(np.uint8)\n",
    "    return hog_image_uint8\n",
    "\n",
    "def read_and_store_modified_chess_images():\n",
    "    def fen_from_position(position, fen_string):\n",
    "        rows = position // 8\n",
    "        cols = position % 8\n",
    "        \n",
    "        # Get the character at the corresponding position in the FEN string\n",
    "        character = fen_string[rows * 8 + cols]\n",
    "\n",
    "        # If the character is a number, return that many empty squares\n",
    "        if character.isdigit():\n",
    "            return ' ' * int(character)\n",
    "        else:\n",
    "            return character\n",
    "\n",
    "    def fen_from_filename(filename):\n",
    "        # Split the filename by '/'\n",
    "        parts = filename.split('/')\n",
    "        # Remove File Extension\n",
    "        fen_part = parts[-1].split('.')[0]\n",
    "\n",
    "        # Replace digits with spaces\n",
    "        fen_string = ''.join([' ' * int(char) if char.isdigit() else char for char in fen_part])\n",
    "\n",
    "        # Remove dashes\n",
    "        fen_string = fen_string.replace('-', '')\n",
    "\n",
    "        return fen_string\n",
    "\n",
    "    def loadImages(src, fileNames, destinationPickleFile, limit):\n",
    "        data = {'fenstring': [], 'data': []}\n",
    "        count = 0\n",
    "\n",
    "\n",
    "        for file in fileNames:\n",
    "            print(\"File:\", file, \"Count:\", count)\n",
    "\n",
    "            if count >= limit:\n",
    "                break\n",
    "            \n",
    "            if file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "                im = imread(os.path.join(src, file))\n",
    "                fenString = fen_from_filename(file)\n",
    "\n",
    "                patches = view_as_blocks(im, block_shape=(block_height, block_width, num_channels)).reshape(-1, block_height, block_width, num_channels)\n",
    "                spaceTilesStored, boardPosition = 0, 0\n",
    "                \n",
    "                for patch in patches:\n",
    "                    patchType = fen_from_position(boardPosition, fenString)\n",
    "                    if patchType == ' ':\n",
    "                        if spaceTilesStored > NUM_SPACES_PER_BOARD:\n",
    "                            continue\n",
    "                        spaceTilesStored += 1\n",
    "                    \n",
    "                    hog_features = HogTransform(patch)\n",
    "                    data['data'].append(hog_features)\n",
    "                    data['fenstring'].append(patchType)\n",
    "                    boardPosition += 1\n",
    "\n",
    "            count += 1\n",
    "        joblib.dump(data, destinationPickleFile)\n",
    "        print(len(data))\n",
    "\n",
    "    random.shuffle(train)  # Shuffle the file names list to pick a random file\n",
    "    loadImages(zipFilePath, train, PICKLE_PATH, NUM_TRAINING_IMAGES)\n",
    "\n",
    "read_and_store_modified_chess_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Pickle File For Image Training\n",
    "def load_pickle_file(file_path):\n",
    "    try:\n",
    "        data = joblib.load(file_path)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading pickle file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the pickle file and output it to a variable\n",
    "loaded_train_data = load_pickle_file(PICKLE_PATH)\n",
    "\n",
    "print(\"Num tiles stored: \" + str(len(loaded_train_data['data'])))\n",
    "\n",
    "first_image = loaded_train_data['data'][1]\n",
    "print(loaded_train_data['fenstring'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads Board Images For Testing Purposes\n",
    "def load_test_images(src, fileNames, limit):\n",
    "    count = 0\n",
    "    testImages = []\n",
    "    for file in fileNames[:NUM_TESTING_IMAGES]:\n",
    "        print(\"File:\", file, \"Count:\", count)\n",
    "        if count >= limit:\n",
    "            break\n",
    "        if file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "            im = imread(os.path.join(src, file))\n",
    "            fenString = file\n",
    "            testImages.append((im, fenString))\n",
    "            count += 1\n",
    "    return testImages\n",
    "\n",
    "random.shuffle(test)  # Shuffle the file names list to pick a random file\n",
    "loaded_test_images = load_test_images(zipFilePath, test, NUM_TESTING_IMAGES)\n",
    "first_image = loaded_test_images[0][0]\n",
    "plt.imshow(first_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_Predict_Individual_Pieces():\n",
    "    \n",
    "    X = np.array(loaded_train_data['data'])\n",
    "    y = np.array(loaded_train_data['fenstring'])\n",
    "\n",
    "    # Filter out data where fenstring is not ' '\n",
    "    X_filtered = [X[i] for i, fenstring in enumerate(loaded_train_data['fenstring']) if fenstring != ' ']\n",
    "    y_filtered = [fenstring for fenstring in loaded_train_data['fenstring'] if fenstring != ' ']\n",
    "\n",
    "    # Flatten each HOG image in X_filtered\n",
    "    X_flat_filtered = [img.flatten() for img in X_filtered]\n",
    "\n",
    "    # Convert to numpy array\n",
    "    X_flat_filtered = np.array(X_flat_filtered)\n",
    "\n",
    "    # Encode FEN strings into numerical labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded_filtered = label_encoder.fit_transform(y_filtered)\n",
    "\n",
    "    # Split the filtered data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_flat_filtered, y_encoded_filtered, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train SVM classifier\n",
    "    svm_classifier = SVC(kernel='linear')\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict FEN string labels for the test set\n",
    "    y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Display confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion_mat, display_labels=label_encoder.classes_)\n",
    "    disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='vertical')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "SVM_Predict_Individual_Pieces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partitions the training data for use in the SVM classifier\n",
    "def SVM_Partition_Data():\n",
    "    X = np.array(loaded_train_data['data'])\n",
    "    y = np.array(loaded_train_data['fenstring'])\n",
    "\n",
    "    # Filter out data where fenstring is not ' '\n",
    "    X_filtered = [X[i] for i, fenstring in enumerate(loaded_train_data['fenstring']) if fenstring != 'l']\n",
    "    y_filtered = [fenstring for fenstring in loaded_train_data['fenstring'] if fenstring != 'l']\n",
    "\n",
    "    # Flatten each HOG image in X_filtered\n",
    "    X_flat_filtered = [img.flatten() for img in X_filtered]\n",
    "\n",
    "    # Convert to numpy array\n",
    "    X_flat_filtered = np.array(X_flat_filtered)\n",
    "\n",
    "    # Encode FEN strings into numerical labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded_filtered = label_encoder.fit_transform(y_filtered)\n",
    "\n",
    "    # Split the filtered data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_flat_filtered, y_encoded_filtered, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = SVM_Partition_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits the training model to the SVM model\n",
    "def SVM_Fit_Model():\n",
    "\n",
    "    # Train SVM classifier\n",
    "    # Define the pipeline with the SVM classifier\n",
    "    svm_classifier = Pipeline(steps=[ \n",
    "        (\"svm\", SVC(kernel='linear', max_iter=2000, random_state=42, probability=True, C = .1, coef0= 0, gamma = .1)) \n",
    "    ])\n",
    "\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "    joblib.dump(svm_classifier, 'svm_classifier.pkl')\n",
    "\n",
    "SVM_Fit_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts the testing boards\n",
    "def SVM_Classifier():\n",
    "    def list_to_fen(input_list):\n",
    "        fen_string = \"\"\n",
    "        empty_count = 0\n",
    "        line_count = 0\n",
    "        \n",
    "        for item in input_list:\n",
    "            if line_count > 7:\n",
    "                if empty_count > 0:\n",
    "                    fen_string += str(empty_count)\n",
    "                    empty_count = 0\n",
    "                fen_string += str('-')\n",
    "                line_count = 0\n",
    "\n",
    "            line_count += 1\n",
    "            if item == ' ':\n",
    "                empty_count += 1\n",
    "                \n",
    "            else:\n",
    "                if empty_count > 0:\n",
    "                    fen_string += str(empty_count)\n",
    "                    empty_count = 0\n",
    "                fen_string += str(item)\n",
    "        \n",
    "        if empty_count > 0:\n",
    "            fen_string += str(empty_count)\n",
    "        \n",
    "        # Removing ',', ']', and '[' from the fen_string\n",
    "        fen_string = fen_string.replace(\"'\", '').replace(']', '').replace('[', '')\n",
    "        \n",
    "        return fen_string\n",
    "\n",
    "    def extract_fen_from_path(file_path):\n",
    "        parts = file_path.split('/')\n",
    "        parts2 = parts[1].split('.')\n",
    "        return parts2[0]\n",
    "\n",
    "    def SVM_Predict_Test_Board():\n",
    "        correct = 0\n",
    "        incorrect_chars = 0\n",
    "        for image, _ in loaded_test_images:\n",
    "            transformed_image = image\n",
    "            patches = view_as_blocks(image, block_shape=(block_height, block_width, num_channels)).reshape(-1, block_height, block_width, num_channels)\n",
    "            \n",
    "            predicted_fenstring = []\n",
    "\n",
    "            for patch in patches:\n",
    "\n",
    "                #hog_features = HogTransform(patch)\n",
    "                hog_features = patch\n",
    "        \n",
    "                flattened_features = hog_features.flatten()  # Flatten the features\n",
    "                predicted_outcome = svm_classifier.predict([flattened_features[:2500]])\n",
    "                label_encoder = LabelEncoder()\n",
    "                predicted_class = label_encoder.inverse_transform(predicted_outcome) \n",
    "\n",
    "                predicted_fenstring.append(predicted_class)\n",
    "            predicted_fenstring = list_to_fen(predicted_fenstring)\n",
    "            actual_fenstring = extract_fen_from_path(_)\n",
    "            print(\"Predicted String: \" + predicted_fenstring)\n",
    "            print(\"Actual String: \" + actual_fenstring)\n",
    "            if predicted_fenstring == actual_fenstring:\n",
    "                print(\"The strings are the same.\")\n",
    "                correct += 1\n",
    "            else:\n",
    "                print(\"The strings are different.\")\n",
    "                # Count the number of different characters\n",
    "                for pred_char, actual_char in zip(predicted_fenstring, actual_fenstring):\n",
    "                    if pred_char != actual_char:\n",
    "                        incorrect_chars += 1\n",
    "            print(incorrect_chars)\n",
    "        total_images = correct + incorrect_chars\n",
    "        print(incorrect_chars / total_images)\n",
    "        return\n",
    "\n",
    "    svm_classifier = load_pickle_file('svm_classifier.pkl')\n",
    "\n",
    "    # Predict FEN string labels for the test set\n",
    "    y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "    SVM_Predict_Test_Board()\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Get the unique class labels predicted by the classifier\n",
    "    unique_labels = np.unique(np.concatenate((y_test, y_pred)))\n",
    "\n",
    "    # Display confusion matrix with correct labels\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion_mat, display_labels=label_encoder.inverse_transform(unique_labels))\n",
    "    disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='vertical')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "SVM_Classifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
