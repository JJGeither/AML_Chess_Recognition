{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in test:  20000\n",
      "Files in train:  80000\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "# opens the chess boards.zip file into the chessBoards object\n",
    "zipFilePath = './archive.zip'\n",
    "chessBoards = ZipFile(zipFilePath, 'r')\n",
    "\n",
    "#datasetTest = []\n",
    "#datasetTrain = []\n",
    "test = []\n",
    "train = []\n",
    "newpath = True\n",
    "\n",
    "# extract the file names from the train and test folders in the zip archive\n",
    "for file in chessBoards.namelist():\n",
    "    # fills the file names from within the dataset subfolder\n",
    "    \"\"\"if file[:13] == 'dataset/test/':\n",
    "        datasetTest.append(file)\n",
    "    if file[:14] == 'dataset/train/':\n",
    "        datasetTrain.append(file)\"\"\"\n",
    "\n",
    "    if file[:4] == 'test':\n",
    "        test.append(file)\n",
    "    if file[:5] == 'train':\n",
    "        train.append(file)\n",
    "\n",
    "    # find any new file paths not accounted for\n",
    "    \"\"\"if file[:13] != 'dataset/test/' and \\\n",
    "        file[:14] != 'dataset/train/' and \\\n",
    "        file[:4] != 'test'and \\\n",
    "        file[:5] != 'train' and \\\n",
    "        newpath:\n",
    "        print(\"new path: \", file)\n",
    "        newpath = False\"\"\"\n",
    "\n",
    "print(\"Files in test: \", len(test))\n",
    "print(\"Files in train: \", len(train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted and saved to .\\test_data_100.pickle\n",
      "Data extracted and saved to .\\train_data_1000.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import random\n",
    "\n",
    "# Extracts the data from the zip file and saves it to a pickle file\n",
    "#\n",
    "# @param[in] zipFilePath - the path to the zip file\n",
    "# @param[in] outputPickleFile - the path to the pickle file to save the data to\n",
    "# @param[in] directory - the directory within the zip file to extract the data from\n",
    "# @param[in] sampleAmount - the number of samples to extract from the zip file\n",
    "def extractData(zipFilePath, outputPickleFile, directory='test/', sampleAmount=None):\n",
    "    data = []\n",
    "\n",
    "    with ZipFile(zipFilePath, 'r') as chess_boards:\n",
    "        for file_name in chess_boards.namelist():\n",
    "            if file_name.startswith(directory):\n",
    "                # Extract FEN string from file name\n",
    "                fen_string = file_name.split('/')[-1]\n",
    "\n",
    "                # Extract image bytes and convert to PIL Image\n",
    "                with chess_boards.open(file_name) as image_file:\n",
    "                    image_bytes = image_file.read()\n",
    "                    image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "                    # Converts image to grayscale\n",
    "                    image = image.convert('L')\n",
    "\n",
    "                # Append FEN string and image to data\n",
    "                data.append((fen_string, image))\n",
    "\n",
    "                # Check if the desired number of samples is reached\n",
    "                if sampleAmount is not None and len(data) >= sampleAmount:\n",
    "                    break\n",
    "\n",
    "    # Get the directory path and base filename\n",
    "    output_dir, base_filename = os.path.split(outputPickleFile)\n",
    "    \n",
    "    # Include the number of samples in the base filename\n",
    "    if sampleAmount is not None:\n",
    "        base_filename = f\"{os.path.splitext(base_filename)[0]}_{sampleAmount}.pickle\"\n",
    "    \n",
    "    # Construct the full output pickle file path\n",
    "    outputPickleFile = os.path.join(output_dir, base_filename)\n",
    "\n",
    "    # Save data to pickle file\n",
    "    with open(outputPickleFile, 'wb') as pickle_file:\n",
    "        pickle.dump(data, pickle_file)\n",
    "\n",
    "    print(f\"Data extracted and saved to {outputPickleFile}\")\n",
    "\n",
    "# Entry point to start the process of pickling the data\n",
    "def pickleData():\n",
    "    zipFilePath = './archive.zip'\n",
    "    outputPickleFile = './test_data.pickle'\n",
    "    extractData(zipFilePath, outputPickleFile, \"test/\", 100)\n",
    "\n",
    "    outputPickleFile = './train_data.pickle'\n",
    "    extractData(zipFilePath, outputPickleFile, \"train/\", 1000)\n",
    "\n",
    "pickleData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from pickle file...\n",
      "Extracting images and labels from training data...\n",
      "Training model...\n",
      "Model trained\n",
      "Loading test data from pickle file...\n",
      "Extracting images and labels from test data...\n",
      "Predicting labels...\n",
      "Evaluating accuracy...\n",
      "Model accuracy: 0.0\n",
      "Actual: 1B1K2k1-p1bp4-1q6-8-B5N1-5N2-2P1q3-N2R2B1.jpeg, Predicted: 1B1B2K1-1B6-5N2-6k1-8-8-8-4nq2.jpeg\n",
      "Actual: 1B6-2P5-8-3P4-q1n5-1b2KP2-4Bp2-5k2.jpeg, Predicted: 1B1B3R-8-1b2k3-8-2n5-1rK5-b7-8.jpeg\n",
      "Actual: 1B1B1K2-3p1N2-6k1-R7-5P2-4q3-7R-1B6.jpeg, Predicted: 1B1B4-4R3-2R2p2-K7-8-3b3r-2Q4P-R2k4.jpeg\n",
      "Actual: 1B6-8-3K2B1-8-8-6R1-8-5k2.jpeg, Predicted: 1B1BK3-7b-3Np3-4N3-2p1r2P-2r5-8-5k1b.jpeg\n",
      "Actual: 1B1Q4-1n1kB3-1N6-B1K5-7r-1R2RN2-r6q-5n2.jpeg, Predicted: 1B1K3k-8-8-2r4R-2b5-8-7b-8.jpeg\n",
      "Actual: 1B1K2k1-p1bp4-1q6-8-B5N1-5N2-2P1q3-N2R2B1.jpeg, Predicted: 1B1K4-1bb3Bb-4P3-5R2-R7-8-8-6k1.jpeg\n",
      "Actual: 1B1K2k1-p1bp4-1q6-8-B5N1-5N2-2P1q3-N2R2B1.jpeg, Predicted: 1B1K4-1p5N-7p-1qp5-n1P5-8-6k1-b7.jpeg\n",
      "Actual: 1B1K2k1-p1bp4-1q6-8-B5N1-5N2-2P1q3-N2R2B1.jpeg, Predicted: 1B1K4-2b5-8-8-R3R2P-5k2-N3R1r1-1r2RR2.jpeg\n",
      "Actual: 1B1K4-1R3P2-4B3-N7-8-8-r5N1-1r2kr2.jpeg, Predicted: 1B1K4-3B4-3p4-8-4k3-6p1-2B5-nq6.jpeg\n",
      "Actual: 1B6-1Bb5-3Q4-7p-4Krk1-b3QN1P-8-2r5.jpeg, Predicted: 1B1K4-3N1k1P-6Q1-3r1n2-8-3p1NNN-8-3b2rR.jpeg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Trains a model using the training data from the pickle file\n",
    "#\n",
    "# @param[in] trainingDataFile - the path to the pickle file containing the training data\n",
    "# @return - the trained Random Forest model\n",
    "def trainModel(trainingDataFile):\n",
    "    # Load the training data from the pickle file\n",
    "    print(\"Loading training data from pickle file...\")\n",
    "    with open(trainingDataFile, 'rb') as file:\n",
    "        trainingData = pickle.load(file)\n",
    "\n",
    "    # Extract the images and labels from the data\n",
    "    print(\"Extracting images and labels from training data...\")\n",
    "    X_train = np.array([np.array(data[1]).flatten() for data in trainingData])\n",
    "    y_train = [data[0] for data in trainingData]\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    print(\"Training model...\")\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=None)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluateModel(model, testDataFile):\n",
    "    # Load the test data from the pickle file\n",
    "    print(\"Loading test data from pickle file...\")\n",
    "    with open(testDataFile, 'rb') as file:\n",
    "        testData = pickle.load(file)\n",
    "\n",
    "    # Extract the images and labels from the data\n",
    "    print(\"Extracting images and labels from test data...\")\n",
    "    X_test = np.array([np.array(data[1]).flatten() for data in testData])\n",
    "    y_test = [data[0] for data in testData]\n",
    "\n",
    "    # Predict the labels using the model\n",
    "    print(\"Predicting labels...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model using accuracy\n",
    "    print(\"Evaluating accuracy...\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model accuracy: {accuracy}\")\n",
    "\n",
    "    for actual, pred in zip(y_pred[:10], y_test[:10]):\n",
    "        print(f\"Actual: {actual}, Predicted: {pred}\")\n",
    "\n",
    "# Entry point to train the model and evaluate it\n",
    "def main():\n",
    "\n",
    "    # Train\n",
    "    model = trainModel('./train_data_1000.pickle')\n",
    "    print(\"Model trained\")\n",
    "\n",
    "    # Evaluate\n",
    "    evaluateModel(model, './test_data_100.pickle')\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
